README.md

This repository contains several Jupyter iPython Notebooks solving data analysis, feature transformation and engineering, feature selection, modeling, evaluation and predictions coverning various industry sectors namely 
- Medical insurance - Claim prediction given independent variables using multivariate polynimial regression, 
- Deposit banking - Customer churn prediction using Logistic Regression,
- Banking - Customer segmentation using kMeans
- Demographic census - Demographic clustering using kPrototype/kMeans, 
- Investment banking - Stock Price prediction using Ramdom Forest Regressor, 
- Credit score - Credit Score classification using kNN.
- Groceries retail - Market Basket Analysis using Apriori
- Financial Tweets Sentiment Analysis - Natural Language Processing (NLP) with SVM
- House Price Prediction - Using XGBoost Regressor

The notebooks in this portfolio cover several supervised and unsupervised machine lerning algorithms for data modeling namely 
- Polynomial multi-variate regression, 
- Logistic Regression, 
- k-Means/k-Prototype (k-Means) clustering, 
- Random Forest Ensemble,
- k-Nearest Neighbor (KNN) classification
- Apriori Association algorithm
- Natural Language Porcessing (NLP) with TF-IDF, Lemmatization, Stemming
- Support Vector Machine (SVM)
- XGBoost

The notebooks in this repository mostly follows the CRISP-DM methodology.

CRISP-DM: Cross Industry Standard Process for Data Mining:
1. Business Understanding
2. Data Understanding
3. Data Preparation
	Data cleaning: fixing incomplete or erroneous data
	Data transformation: formatting the data
	Data reduction: reducing data to its simplest form
	Feature engineering: selecting and transforming variables to work better with machine learning
4. Modeling
5. Evaluation

The Python technolgies packages used in these notebooks include but not limited to the following:
- Pandas
- Seaborn
- Matplotlib
- Scipy
- Numpy
- Scikit-learn
- imblearn
- kmodes
- plotnine
- plotly-
- wordcloud
- spacy
- re (regular expression)
- TfidfVectorizer
- LabelEncoder
- RandomOverSampler
- GridSearchCV
- Pipeline
- pickle
- SelectFromModel
- mlxtend
- RandomSearchCV
- CategoricalEncoder
- TargetEncoder

Data has mostly been sourced from public license sources like kaggle.com or other open license sources. All data are believed to be collected from real life.

The following concepts widely used in the Data Science/Machine Learning/Deep Learning industry have been used in the notebooks in this repository:
- Categorical to numerical encoding
- Pipelines
- Visualization
- PCA
- Imbalanced Data handling
- Outlier Detection and removal
- Correlation Heatmap
- Feature Transform
- Feature Scaling
- Feature Selection (SelectFromModel)
- Train Test Split
- Hyperparameter tuning
- Stochastic Gradient Descent
- Model evaluation using R-squared, Mean Squared Error, accuracy, F1 score, ROC AUC Score and Confusion matrix
- k-fold Cross Validation  (GridSearchCV)
- Pickle and joblib for serializing and deserializing models

My LinkedIn profile: https://www.linkedin.com/in/partha-das-9650b6196

